{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "yKp6pJcXbQPO",
   "metadata": {
    "id": "yKp6pJcXbQPO"
   },
   "source": [
    "### Preparation ###\n",
    "Create folders and upload fp-dataset into the dataset folder.\n",
    "Upload the Protein-Bert and predictor model into the models folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "648f1dfb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "648f1dfb",
    "outputId": "ed44c66f-d180-4888-c13c-f98fdc322330"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "seed = 0\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if(device == \"cuda\"):\n",
    "    torch.cuda.synchronize()\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "62bdce21",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "62bdce21",
    "outputId": "72626d17-2867-407e-afa3-beba34986fcc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ein Unterverzeichnis oder eine Datei mit dem Namen \"models\" existiert bereits.\n"
     ]
    }
   ],
   "source": [
    "!mkdir models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f34413ef",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f34413ef",
    "outputId": "0c4c895e-5524-49f6-8f81-13208fa32154"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ein Unterverzeichnis oder eine Datei mit dem Namen \"datasets\" existiert bereits.\n"
     ]
    }
   ],
   "source": [
    "!mkdir datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84777a6b",
   "metadata": {
    "id": "84777a6b"
   },
   "source": [
    "### Architecture design ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d8a8598b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d8a8598b",
    "outputId": "27365cfa-a69e-456c-eb0c-c984abd461c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: protein_bert_pytorch in c:\\users\\prophet.desktop-uufa83j\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (0.1.0)\n",
      "Requirement already satisfied: torch>=1.6 in c:\\users\\prophet.desktop-uufa83j\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from protein_bert_pytorch) (1.9.0)\n",
      "Requirement already satisfied: einops>=0.3 in c:\\users\\prophet.desktop-uufa83j\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from protein_bert_pytorch) (0.4.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\prophet.desktop-uufa83j\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch>=1.6->protein_bert_pytorch) (3.7.4.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\Prophet.DESKTOP-UUFA83J\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install protein_bert_pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "849b256f",
   "metadata": {
    "id": "849b256f"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from protein_bert_pytorch import ProteinBERT, PretrainingWrapper\n",
    "annotation_max = 18000  # 2350\n",
    "\n",
    "def proteinBERT_model():\n",
    "  return ProteinBERT(\n",
    "      num_tokens = 25,\n",
    "      num_annotation = annotation_max,\n",
    "      dim = 512,\n",
    "      dim_global = 256,\n",
    "      depth = 6,\n",
    "      narrow_conv_kernel = 9,\n",
    "      wide_conv_kernel = 9,\n",
    "      wide_conv_dilation = 5,\n",
    "      attn_heads = 8,\n",
    "      attn_dim_head = 64,\n",
    "      local_to_global_attn = False,\n",
    "      local_self_attn = True,\n",
    "      num_global_tokens = 2,\n",
    "      glu_conv = False\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "gg5ma5GpUGmz",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gg5ma5GpUGmz",
    "outputId": "86b0ea54-3b2d-4f55-e9e1-2f53af69919a"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Identity(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Identity, self).__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x\n",
    "    \n",
    "class predictorNet(torch.nn.Module):\n",
    "    def __init__(self, dropout):\n",
    "        super().__init__()\n",
    "        self.flatten = torch.nn.Flatten(start_dim=1)\n",
    "        self.linear1 = torch.nn.Linear(179200, 64)\n",
    "        self.linear3 = torch.nn.Linear(64, 2)\n",
    "        self.dropout = torch.nn.Dropout(p=dropout)\n",
    "        \n",
    "    def forward(self, x, dropout=True):\n",
    "        x = self.flatten(x)\n",
    "        if(dropout): x = self.dropout(x)\n",
    "        x = self.linear1(x)\n",
    "        x = torch.nn.functional.softplus(x)\n",
    "        x = self.linear3(x)\n",
    "        return x\n",
    "\n",
    "model = torch.load('models/pretrained_drp2_005_m_ex_em_1.pt', map_location=torch.device(device))\n",
    "model_predictor = torch.load('models/pretrained_drp2_005_b_ex_em_1.pt', map_location=torch.device(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pwuy1qqOXz53",
   "metadata": {
    "id": "pwuy1qqOXz53"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d7d01c62",
   "metadata": {
    "id": "d7d01c62"
   },
   "source": [
    "### Data preparation ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7c4d0a04",
   "metadata": {
    "id": "7c4d0a04"
   },
   "outputs": [],
   "source": [
    "def clean(result):\n",
    "    if(result!=None):\n",
    "        return result\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "df6ac481",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "df6ac481",
    "outputId": "5e9b3d7e-c4ea-4afa-fe57-58697e80b659"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 21, 17, 22, 23]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_acid2int = {'A' : 1,'R' : 2,'N' : 3,'D' : 4,'C' : 5,'Q' : 6,'E' : 7,'G' : 8,'H' : 9,'I' : 10,\n",
    "          'L' : 11,'K' : 12,'M' : 13,'F' : 14,'P' : 15,'S' : 16,'T' : 17,'W' : 18,'Y' : 19,\n",
    "          'V' : 20,'B' : 21,'Z' : 22,'X' : 23,'*' : 24,'-' : 25,'?' : 0}\n",
    "\n",
    "def acid2int(seq : str) -> list:\n",
    "    return [(_acid2int[i]) for i in seq]\n",
    "\n",
    "x = 'ABTZX'\n",
    "acid2int(x) # returns [1, 21, 17, 22, 23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7734bf10",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7734bf10",
    "outputId": "920a1b77-4557-45d3-d373-2d1a5c49bdb1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "797\n",
      "617\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "   \n",
    "# Configuration\n",
    "min_seq=25\n",
    "max_seq=350\n",
    "    \n",
    "# Opening JSON file\n",
    "f = open('datasets/fp_database.json', encoding='UTF-8')\n",
    "normalizer = [0.002, 0.002, 1, 0.01]\n",
    "\n",
    "fp_dataset = []\n",
    "name_list = []\n",
    "# returns JSON object as \n",
    "# a dictionary\n",
    "data = json.load(f)\n",
    "# Iterating through the json\n",
    "# list\n",
    "print(len(data))\n",
    "for index, i in enumerate(data):\n",
    "    try:  # To read incomplete files and make this method more robust\n",
    "        name=i['name']\n",
    "        seq=i['seq']\n",
    "        em=i['states'][0]['em_max']\n",
    "        ex=i['states'][0]['ex_max']\n",
    "        qy=i['states'][0]['qy']\n",
    "        br=i['states'][0]['brightness']\n",
    "        if(index==0):\n",
    "            print(name)\n",
    "            print()\n",
    "            print(seq)\n",
    "            print(qy)\n",
    "            print(br)\n",
    "            print(em)\n",
    "            print(ex)\n",
    "        if(seq!=None) and (em!=None) and (ex!=None): #  and (qy!=None):\n",
    "            if(len(seq)>min_seq) and (len(seq)<max_seq) and (em>0) and (ex>0):\n",
    "                seq_ = seq + \"\".join([\"?\"]*(max_seq-len(seq)))\n",
    "                label = torch.tensor([em, ex]).float()\n",
    "                sequence = torch.tensor(acid2int(seq_))\n",
    "                fp_dataset.append([sequence, torch.tensor([label[0]*normalizer[0], label[1]*normalizer[1]])])\n",
    "                # fp_dataset.append([sequence, torch.tensor([torch.tensor([em]).float()*normalizer[0]])])\n",
    "                name_list.append(name)\n",
    "    except:\n",
    "        True\n",
    "# Closing file\n",
    "f.close()\n",
    "\n",
    "print(len(fp_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fb97cb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "normalizer = [0.002, 0.002, 1, 0.01]\n",
    "with (open(\"datasets/test_dataset_split_fp.pkl\", \"rb\")) as openfile:\n",
    "    [train_set, test_set] = pickle.load(openfile)  \n",
    "# print(test_set[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "06842141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 'mcavRFP'], [1, 'cgfTagRFP'], [2, 'AQ14'], [3, 'rsFusionRed1'], [4, 'mRhubarb713'], [5, 'super-TagRFP'], [6, 'G1'], [7, 'Superfolder CFP'], [8, 'LanFP2'], [9, 'mEosFP-F173S'], [10, 'GFPxm18uv'], [11, 'mStable'], [12, 'mNeptune2.5'], [13, 'iRFP682'], [14, 'ShyRFP'], [15, 'deGFP1'], [16, 'mMiCy'], [17, 'sarcGFP'], [18, 'mEos4b'], [19, 'mEGFP'], [20, 'Folding Reporter GFP'], [21, 'mStrawberry'], [22, 'mCherry-XL'], [23, 'mEos2-A69T'], [24, 'mEYFP'], [25, 'Topaz'], [26, 'mNeptune2'], [27, 'd-RFP618'], [28, 'GFP(E222G)'], [29, 'h2-3'], [30, 'mGrape1'], [31, 'Skylan-NS'], [32, 'mGeos-S'], [33, 'mCherry'], [34, 'BDFP1.6'], [35, 'D10'], [36, 'RFP630'], [37, 'ptilGFP'], [38, 'eforCP'], [39, 'EBFP1.2'], [40, 'roGFP1-R8'], [41, 'scubRFP'], [42, 'mNeonGreen'], [43, 'rsFolder'], [44, 'Enhanced Cyan-Emitting GFP'], [45, 'avGFP'], [46, 'Sapphire'], [47, 'W1C'], [48, 'mRFP1-Q66S'], [49, 'mCardinal']]\n"
     ]
    }
   ],
   "source": [
    "# Get all corresponding protein names for the test-set used as the unseen reference during training process\n",
    "protein_name_list = []\n",
    "for protein_index, test_protein in enumerate(test_set):\n",
    "    for index, element in enumerate(fp_dataset):\n",
    "        if torch.all(test_protein[0].eq(element[0])):\n",
    "            protein_name_list.append([protein_index, name_list[index]])\n",
    "            continue\n",
    "print(protein_name_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9579d0e0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9579d0e0",
    "outputId": "b91bc8e9-7c4b-43c5-9c20-45dc9c5bceda"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "batch_size=16\n",
    "train_dataloader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Sizes of resulting train and test-set\n",
    "print(len(train_dataloader))\n",
    "print(len(test_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "df08dd31",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "df08dd31",
    "outputId": "b1202540-1fac-45ad-93db-bedc0deb5ab8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "16\n",
      "16\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "for index, element in enumerate(test_dataloader):\n",
    "    print(len(element[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012234c9",
   "metadata": {
    "id": "012234c9"
   },
   "source": [
    "### Training process ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "41ea6b39",
   "metadata": {
    "id": "41ea6b39"
   },
   "outputs": [],
   "source": [
    "global Epoch, lc_train, lc_test\n",
    "Epoch = 0\n",
    "lc_train, lc_test = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "lGcG6pItGJqZ",
   "metadata": {
    "id": "lGcG6pItGJqZ"
   },
   "outputs": [],
   "source": [
    "lr_factor = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1db73dc5",
   "metadata": {
    "id": "1db73dc5"
   },
   "outputs": [],
   "source": [
    "# do the following in a loop for a lot of sequences and annotations\n",
    "from tqdm.notebook import tqdm\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "# only spectra\n",
    "def train_supervised(_model, _predictor, dataloader_train, dataloader_test, lr=1, epochs=10, dropout=True, dropout_flipping=False):\n",
    "    dropout = dropout\n",
    "    global Epoch\n",
    "    optimizer = torch.optim.Adam(_model.parameters(),    lr=lr*0.0000001*lr_factor)\n",
    "    optimizer2 = torch.optim.Adam(_predictor.parameters(), lr=lr*0.0000002*lr_factor)  \n",
    "    summed_loss = 0.0\n",
    "    for epoch in range(epochs):\n",
    "        Epoch+=1\n",
    "        if(Epoch%10==1):\n",
    "            print(\"epoch: \" + str(Epoch-1))\n",
    "        summed_loss = 0.0\n",
    "        with tqdm(total=len(dataloader_train)) as pbar:\n",
    "            train_index=0\n",
    "            # training process\n",
    "            for index, (inputs,labels) in enumerate(dataloader_train):\n",
    "                optimizer.zero_grad()\n",
    "                optimizer2.zero_grad()\n",
    "\n",
    "                annotation_list = [[0]*512]*inputs.shape[0]\n",
    "                annotation = torch.tensor(annotation_list).float()\n",
    "                mask       = torch.ones(inputs.shape).bool()\n",
    "                \n",
    "                # print(inputs.shape, annotation.shape, mask.shape)\n",
    "                representation, annotation_repr = _model(inputs.to(device), annotation.to(device), mask = mask.to(device))\n",
    "                if(dropout_flipping==True):\n",
    "                  dropout = not dropout\n",
    "                x = _predictor(representation, dropout=dropout)\n",
    "                # print(labels.shape, x.shape)\n",
    "                # print(inputs)\n",
    "                loss = criterion(labels.to(device), x.to(device))\n",
    "                summed_loss+=loss.detach()\n",
    "                train_index += inputs.shape[0]\n",
    "                \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                optimizer2.step()\n",
    "                pbar.set_description(f'train_loss: {\"%.5f\" % (summed_loss/train_index*100)}')\n",
    "                pbar.update(1)\n",
    "            \n",
    "            # evaluation process\n",
    "            test_index = 0\n",
    "            summed_test_loss = 0\n",
    "            optimizer.zero_grad()\n",
    "            optimizer2.zero_grad()   \n",
    "            for _, (inputs,labels) in enumerate(dataloader_test):\n",
    "                \n",
    "                annotation_list = [[0]*512]*inputs.shape[0]\n",
    "                annotation = torch.tensor(annotation_list).float()\n",
    "                mask       = torch.ones(inputs.shape).bool()\n",
    "                representation, annotation_repr = _model(inputs.to(device), annotation.to(device), mask = mask.to(device))\n",
    "                x = _predictor(representation, dropout=False)\n",
    "                loss = criterion(labels.to(device), x.to(device))\n",
    "                test_index += inputs.shape[0]\n",
    "                summed_test_loss+=loss.detach()\n",
    "            \n",
    "            lc_train.append(summed_loss/train_index) \n",
    "            lc_test.append(summed_test_loss/test_index)    \n",
    "            pbar.set_description(f'train_loss: {\"%.5f\" % (summed_loss/train_index*100)}, test_loss: {\"%.5f\" % (summed_test_loss/test_index*100)}')\n",
    "            pbar.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4ca59f72",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4ca59f72",
    "outputId": "96a56394-f9e2-4d84-8bc3-b7cf34252d46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data\n",
      "[[637.0, 637.501], [518.0, 515.618], [625.0, 607.567], [513.0, 510.135], [670.0, 662.628], [490.0, 490.154], [610.0, 604.756]]\n",
      "test_data\n",
      "[[479.0, 501.236], [596.0, 565.441], [682.0, 688.02], [516.0, 528.403], [511.0, 512.878], [485.0, 512.042], [530.0, 512.09]]\n"
     ]
    }
   ],
   "source": [
    "def print_test_instances(dataloader, model, model_predictor):\n",
    "  for index, (inputs,labels) in enumerate(dataloader): \n",
    "      annotation_list = [[0]*512]*inputs.shape[0]\n",
    "      annotation = torch.tensor(annotation_list).float()\n",
    "      mask       = torch.ones(inputs.shape).bool()\n",
    "      token, annotation_logits = model(inputs.to(device), annotation.to(device), mask = mask.to(device))\n",
    "      x = model_predictor(token, dropout=False)\n",
    "      loss = criterion(labels.to(device), x.to(device))\n",
    "      value_list = []\n",
    "      for index in range(inputs.shape[0]):\n",
    "          value_list.append([round((labels[index].cpu().detach().numpy()/normalizer[0])[0],3), \n",
    "                             round((x[index].cpu().detach().numpy()/normalizer[0])[0],3)])  # :2]) # , loss)\n",
    "          if(index>5):\n",
    "            break\n",
    "      print(value_list)\n",
    "      break\n",
    "\n",
    "print(\"train_data\")\n",
    "print_test_instances(train_dataloader, model, model_predictor)\n",
    "print(\"test_data\")\n",
    "print_test_instances(test_dataloader, model, model_predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "9bd3274a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2bd1c8a075a442bbd4e33d122a182d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean error: (12.681, 20.737)\n",
      "\n",
      "\n",
      "test_data\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0336e63be9d4f8cacae74970b91c4c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean error: (28.89, 37.341)\n"
     ]
    }
   ],
   "source": [
    "# Calculate mean square error over the full test-set\n",
    "\n",
    "def calculate_mse(dataloader, model, model_predictor, root=False):\n",
    "    instance_number=0\n",
    "    summed_squared_error_em=0\n",
    "    summed_squared_error_ex=0\n",
    "    with tqdm(total=len(dataloader)) as pbar:\n",
    "        for index, (inputs,labels) in enumerate(dataloader): \n",
    "            annotation = torch.tensor([[0]*512]*inputs.shape[0]).float()\n",
    "            mask       = torch.ones(inputs.shape).bool()\n",
    "            token, annotation_logits = model(inputs.to(device), annotation.to(device), mask = mask.to(device))\n",
    "            x = model_predictor(token, dropout=False)\n",
    "            # print(x.shape)\n",
    "            for index_batch in range(x.shape[0]-1):\n",
    "                instance_number+=1\n",
    "                em_label=(labels[index_batch].cpu().detach().numpy()/normalizer[0])[0]\n",
    "                em_output=(x[index_batch].cpu().detach().numpy()/normalizer[0])[0]\n",
    "                ex_label=(labels[index_batch].cpu().detach().numpy()/normalizer[0])[1]\n",
    "                ex_output=(x[index_batch].cpu().detach().numpy()/normalizer[0])[1]\n",
    "                summed_squared_error_em+=(em_label-em_output)**2\n",
    "                summed_squared_error_ex+=(ex_label-ex_output)**2\n",
    "            mse_em=(summed_squared_error_em/instance_number)\n",
    "            mse_ex=(summed_squared_error_ex/instance_number)\n",
    "            pbar.set_description(f'MSE emission: {\"%.3f\" % mse_em}, MSE excitation: {\"%.3f\" % mse_ex}')\n",
    "            pbar.update(1)\n",
    "        return mse_em, mse_ex\n",
    "    \n",
    "print(\"train_data\")\n",
    "mse_em, mse_ex= calculate_mse(train_dataloader, model, model_predictor)\n",
    "print(\"mean error: \" + str((round(mse_em**0.5,3), round(mse_ex**0.5,3))))\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"test_data\")\n",
    "mse_em, mse_ex= calculate_mse(test_dataloader, model, model_predictor)\n",
    "print(\"mean error: \" + str((round(mse_em**0.5,3), round(mse_ex**0.5,3))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817c1c2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "v2_interpretability_basis.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python39 DeepLearningKernel",
   "language": "python",
   "name": "ipyk3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
